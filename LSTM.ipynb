{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "pd_train=pd.read_csv(\"../../data/train.csv\")\n",
    "pd_test=pd.read_csv(\"../../data/test.csv\")\n",
    "production_year_max=0\n",
    "production_year_min=0\n",
    "model_release_year_max=0\n",
    "model_release_year_min=0\n",
    "distance_driven_max=0\n",
    "distance_driven_min=0\n",
    "Displacement_max=0\n",
    "Displacement_min=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainDatasetComposition(pddata,organize):\n",
    "    brand=pd.unique(pddata[\"브랜드\"])\n",
    "    brand_record=np.copy(brand)\n",
    "    sales_city=pd.unique(pddata[\"판매도시\"])\n",
    "    sales_city_record=np.copy(sales_city)\n",
    "    sales_area=pd.unique(pddata[\"판매구역\"])\n",
    "    sales_area_record=np.copy(sales_area)\n",
    "    vehicle_model=pd.unique(pddata[\"차량모델명\"])\n",
    "    vehicle_model_record=np.copy(vehicle_model)\n",
    "    train_ID=np.array(pddata[\"ID\"])\n",
    "    pddata[\"생산년도\"]=pddata[\"생산년도\"]-2000\n",
    "    pddata[\"모델출시년도\"]=pddata[\"모델출시년도\"]-2000\n",
    "    pddata[\"주행거리\"]=pddata[\"주행거리\"]/10000\n",
    "    \n",
    "    if organize==\"min\":\n",
    "        for i in range(len(brand)):\n",
    "            brand_record[i]=pddata.loc[pddata[\"브랜드\"]==brand[i]][\"가격\"].min()\n",
    "        for i in range(len(sales_city)):\n",
    "            sales_city_record[i]=pddata.loc[pddata[\"판매도시\"]==sales_city[i]][\"가격\"].min()\n",
    "        for i in range(len(sales_area)):\n",
    "            sales_area_record[i]=pddata.loc[pddata[\"판매구역\"]==sales_area[i]][\"가격\"].min()\n",
    "        for i in range(len(vehicle_model)):\n",
    "            vehicle_model_record[i]=pddata.loc[pddata[\"차량모델명\"]==vehicle_model[i]][\"가격\"].min()\n",
    "    elif organize==\"mean\":\n",
    "        for i in range(len(brand)):\n",
    "            brand_record[i]=pddata.loc[pddata[\"브랜드\"]==brand[i]][\"가격\"].mean()\n",
    "        for i in range(len(sales_city)):\n",
    "            sales_city_record[i]=pddata.loc[pddata[\"판매도시\"]==sales_city[i]][\"가격\"].mean()\n",
    "        for i in range(len(sales_area)):\n",
    "            sales_area_record[i]=pddata.loc[pddata[\"판매구역\"]==sales_area[i]][\"가격\"].mean()\n",
    "        for i in range(len(vehicle_model)):\n",
    "            vehicle_model_record[i]=pddata.loc[pddata[\"차량모델명\"]==vehicle_model[i]][\"가격\"].mean()\n",
    "    elif organize==\"max\":\n",
    "        for i in range(len(brand)):\n",
    "            brand_record[i]=pddata.loc[pddata[\"브랜드\"]==brand[i]][\"가격\"].max()\n",
    "        for i in range(len(sales_city)):\n",
    "            sales_city_record[i]=pddata.loc[pddata[\"판매도시\"]==sales_city[i]][\"가격\"].max()\n",
    "        for i in range(len(sales_area)):\n",
    "            sales_area_record[i]=pddata.loc[pddata[\"판매구역\"]==sales_area[i]][\"가격\"].max()\n",
    "        for i in range(len(vehicle_model)):\n",
    "            vehicle_model_record[i]=pddata.loc[pddata[\"차량모델명\"]==vehicle_model[i]][\"가격\"].max()\n",
    "    \n",
    "    \n",
    "    production_year_max=pddata[\"생산년도\"].max()\n",
    "    production_year_min=pddata[\"생산년도\"].min()\n",
    "    model_release_year_max=pddata[\"모델출시년도\"].max()\n",
    "    model_release_year_min=pddata[\"모델출시년도\"].min()\n",
    "    distance_driven_max=pddata[\"주행거리\"].max()\n",
    "    distance_driven_min=pddata[\"주행거리\"].min()\n",
    "    Displacement_max=pddata[\"배기량\"].max()\n",
    "    Displacement_min=pddata[\"배기량\"].min()\n",
    " \n",
    "    pddata[\"생산년도\"]=(pddata[\"생산년도\"]-production_year_min)/(production_year_max-production_year_min)\n",
    "    pddata[\"모델출시년도\"]=(pddata[\"모델출시년도\"]-model_release_year_min)/(model_release_year_max-model_release_year_min)\n",
    "    pddata[\"주행거리\"]=(pddata[\"주행거리\"]-distance_driven_min)/(distance_driven_max-distance_driven_min)\n",
    "    pddata[\"배기량\"]=(pddata[\"배기량\"]-Displacement_min)/(Displacement_max-Displacement_min)\n",
    "\n",
    "    pddata.insert(3,'생산-출시',pddata[\"생산년도\"]-pddata[\"모델출시년도\"])\n",
    "    np_tarin=np.array(pddata)\n",
    "    for i in range(len(np_tarin)):\n",
    "        np_tarin[i,4]=brand_record[np.where(brand==np_tarin[i,4])[0][0]]/brand_record.max()\n",
    "        np_tarin[i,5]=vehicle_model_record[np.where(vehicle_model==np_tarin[i,5])[0][0]]/vehicle_model_record.max()\n",
    "        np_tarin[i,6]=sales_city_record[np.where(sales_city==np_tarin[i,6])[0][0]]/sales_city_record.max()\n",
    "        np_tarin[i,7]=sales_area_record[np.where(sales_area==np_tarin[i,7])[0][0]]/sales_area_record.max()\n",
    "    np_tarin=np.delete(np_tarin,0,axis=1)\n",
    "    \n",
    "    return np_tarin[:,:-1],np_tarin[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train1=copy.copy(pd_train)\n",
    "mean_train_x,mean_train_y=TrainDatasetComposition(pd_train1,\"mean\")\n",
    "mean_train_x=mean_train_x.astype(np.float32)\n",
    "\n",
    "mean_train_y=mean_train_y.astype(np.float32)\n",
    "pd_train1=copy.copy(pd_train)\n",
    "min_train_x,min_train_y=TrainDatasetComposition(pd_train1,\"min\")\n",
    "min_train_x=min_train_x.astype(np.float32)\n",
    "\n",
    "min_train_y=min_train_y.astype(np.float32)\n",
    "pd_train1=copy.copy(pd_train)\n",
    "max_train_x,max_train_y=TrainDatasetComposition(pd_train1,\"max\")\n",
    "\n",
    "max_train_x=max_train_x.astype(np.float32)\n",
    "max_train_y=max_train_y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm_model():\n",
    "    model = K.Sequential()\n",
    "    model.add(layers.LSTM(56, input_shape = (14,1), return_sequences = True))\n",
    "    model.add(layers.LSTM(28,  return_sequences = True))\n",
    "    model.add(layers.LSTM(14,  return_sequences = False))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "    return model\n",
    "\n",
    "def gru_model():\n",
    "    model = K.Sequential()\n",
    "    model.add(layers.GRU(56, input_shape = (14,1), return_sequences = True))\n",
    "    model.add(layers.GRU(28,  return_sequences = True))\n",
    "    model.add(layers.GRU(14, return_sequences = False))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "    return model\n",
    "\n",
    "lstm_Model = lstm_model()\n",
    "gru_Model = gru_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = K.callbacks.ModelCheckpoint(\"../../model/gru/mean/bast_mse.h5\", save_best_only=True)\n",
    "gru_Model.fit(mean_train_x[:-10000],mean_train_y[:-10000],validation_data=(mean_train_x[-10000:],mean_train_y[-10000:]),callbacks=[mc], batch_size = 100, epochs = 2000, verbose = 1)\n",
    "gru_Model.save(\"../../model/gru/mean/mse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "480/480 [==============================] - 13s 16ms/step - loss: 43.6889 - val_loss: 39.6864\n",
      "Epoch 2/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 37.1279 - val_loss: 34.6447\n",
      "Epoch 3/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 33.0965 - val_loss: 31.5238\n",
      "Epoch 4/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 30.7148 - val_loss: 29.7706\n",
      "Epoch 5/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 29.3487 - val_loss: 28.7676\n",
      "Epoch 6/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 28.6210 - val_loss: 28.2717\n",
      "Epoch 7/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 28.2550 - val_loss: 28.0237\n",
      "Epoch 8/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 28.0921 - val_loss: 27.9294\n",
      "Epoch 9/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 28.0384 - val_loss: 27.8898\n",
      "Epoch 10/2000\n",
      "480/480 [==============================] - 7s 15ms/step - loss: 27.3655 - val_loss: 22.2542\n",
      "Epoch 11/2000\n",
      "480/480 [==============================] - 7s 14ms/step - loss: 20.6036 - val_loss: 19.2189\n",
      "Epoch 12/2000\n",
      "136/480 [=======>......................] - ETA: 4s - loss: 18.6789"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mc \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39m../../model/lstm/mean/bast_mse.h5\u001b[39m\u001b[39m\"\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m lstm_Model\u001b[39m.\u001b[39;49mfit(mean_train_x[:\u001b[39m-\u001b[39;49m\u001b[39m10000\u001b[39;49m],mean_train_y[:\u001b[39m-\u001b[39;49m\u001b[39m10000\u001b[39;49m],validation_data\u001b[39m=\u001b[39;49m(mean_train_x[\u001b[39m-\u001b[39;49m\u001b[39m10000\u001b[39;49m:],mean_train_y[\u001b[39m-\u001b[39;49m\u001b[39m10000\u001b[39;49m:]),callbacks\u001b[39m=\u001b[39;49m[mc], batch_size \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, epochs \u001b[39m=\u001b[39;49m \u001b[39m2000\u001b[39;49m, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m lstm_Model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m../../model/lstm/mean/mse.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mc = K.callbacks.ModelCheckpoint(\"../../model/lstm/mean/bast_mse.h5\", save_best_only=True)\n",
    "lstm_Model.fit(mean_train_x[:-10000],mean_train_y[:-10000],validation_data=(mean_train_x[-10000:],mean_train_y[-10000:]),callbacks=[mc], batch_size = 100, epochs = 2000, verbose = 1)\n",
    "lstm_Model.save(\"../../model/lstm/mean/mse.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
